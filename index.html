<meta http-equiv="content-type" content="text/html; charset=windows-1252">
<title>Data Science </title>
  <style type="text/css">
h3,h1 {color: purple;
}
  h2 {
    color: purple;
    background-color: #d8da3d }
ul.paragraph li {
  margin: 1em 0;
}

ul li{
  margin: 0.25em 0;
}
</style>
<meta name="description" content="Data Science">
</head>
<body>




<html><head>

<h1> Twitter Data - Analysis </h1>
<h2> Preliminaries </h2>

<ul>
 <li> My very first step is to re-format the 15K Tweepy status objects in "./data/ml_tweets.bin" into a CSV file. </li>
 <li> Code: "python data_format.py data/ml_tweets.bin"  </li> 
</ul >


<h3> Tweeting frequency : spread over time and user-space </h3>

    <ul> Code : "python data_characteristics.py"  to produce the following two files </ul> 
    <table style="width:75%">  
            <tr> <td> <img src="data/tweet_frequency_monthly.jpg " alt="--", width="75%"> </td>    </tr>
            <tr> <td> <img src="data/tweet_frequency_user_wise.jpg " alt="--", width="75%"> </td>    </tr>
    </table>


    <ul> 
        <li> The temporal spread is too skewed. Almost all of the tweets are from the past 2 months, discouraging trend-analysis </li>
        <li> A quick visualization of user popularity -- with number of followers as a proxy for popularity</li>
    </ul>

   <table style="width:75%">  
            <tr> <td> <img src="data/followers.jpg " alt="--", width="75%"> </td>    </tr>
    </table>


    <ul> 
        <li> Hillary Mason has nearly 100K followers. Contrast that with 50K followers for the Stanford NLP group.!!! </li>
        <li> An explanation is <a href="https://www.quora.com/Why-is-Hilary-Mason-a-prominent-figure-within-the-big-data-community-What-are-her-notable-accomplishments"> here </a> </li>
    </ul>



<h2> Linguistic Analysis -- Topic discovery </h2>
    <table style="width:90%">  
            <tr>  
                 <td> 
                    <p>    What does the text in the dataset tell us. ?  </p>
                 If there is more of historical data, tweets can be analysed for trends in hashtag usage, topic evolution, language changes..etc.
                From a linguistic angle, topic discovery is the most interesting. After experimenting, I settled with the number of topics as 6. 
                Looking at the words associated with these topics, they are most likely to be :
                 </td>  
                 <td> <img src="data/wordcloud.jpg" alt="--", width="100%"> </td> 
           </tr>
    </table>



    
     <l>
     <li> Topic 0: Videos/Graphics. Main keywords: play, hardmaru. </li>
     <li> Topic 1: Discussion.  Tweets of this kind seem to be general discussion, talking about Visa issues in conferences and othe general aspects. Main keywords: think, really good, idea</li>
     <li> Topic 2: ML community news. Mostly mailing-list announcements. Main keywords: neural, example, application, science </li>
     <li> Topic 3: NLP :  Quite similar to topic 2, but NLP focussed. Some popular nlp forums driving these. Main keywords: nlproc, stanfordnlp  </li>
     <li> Topic 4: Google-related:  Mainly announcements related to new developments around Tensorflow. Main keywords: spacy, tensorflow, release,support  </li>
     <li> Topic 5: Academic : There is a higher presence of academic news, driven by ICML conference announcements and academic openings. Main keywords: great, talk, paper, post, student </li>
    </l >

    
        <p>Topic discovery - being an unsupervised problem requires considerable manual examination to fine tune the process. LDA might not be best suited for short-texts such as tweets and further experimentation with other methods such as TF-IDF based clustering.  Entity-recognition for standard concepts like person, organization etc showed less accuracy - perhaps because a dataset-specific trained model is not yet available. Training such a model requires more experimentation/annotation support as well. Below is an illustration that shows the topics on which a user mostly tweets about.  </p>

    <table style="width:75%">  
            <tr> <td> <img src="data/User_to_topic_association.jpg" alt="--", width="120%"> </td>    </tr>
    </table>


<h2> Conclusion </h2>
    <p>Summary  </p>
        <ul>
        <li> Dataset is temporally skewed -- most tweets being from past 2 months -- is not conducive for temporal or trend analysis</li>
        <li> The follower count analysis was interesting and helped discover the leaders of the community such as Hillary Mason</li>
        <li> Topic discovery showed some interesting insights such as the strong associations such as (Google-Related, Tensorflow)  and
            (Academic, icmlconf). A surprising observations is the weak association in (Videos/Graphics, Tensorflow). More manual analysis is needed to explain these phenomenon.
    </ul>
    

     <p> Future work </p>
        <ul>
      <li> The next step is to find the relation between hashtags and the discovered topics from tweet-text. This is is going to be helpful in interpreting a popular hashtag subjectively, for latent inherent concepts that drive it. This task can also be approached in a similar way. That is, similar to how User-to-Topic association was determined, substituting the appropriate hashtags instead of tweeter-ids in the above analysis. </li>
     <li> If historical tweets can be crawled, we can track the change in topic-focus for a user, against time.  </li>
    <li> The current dataset only tell us the follower count - not the actual list of followers and therefore not permitting a social-graph construction. If such information can be secured, we could do social-graph-mining to determine the specific ways in which influence spreads. For example, what are the discernible changes in a user's tweeting pattern, after he starts to follow a certain political leader or after he unfollows a celebrity.  </li>
    </ul>
     

</body></html>
